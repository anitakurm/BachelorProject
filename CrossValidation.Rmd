---
title: "cross-validation"
author: "Anita Kurm"
date: "December 6, 2018"
output: html_document
---
Set-up:
```{r}
#libraries 
pacman::p_load(ggplot2,dplyr,lme4,MuMIn,lmerTest,gstat,stringr,plyr,caret,modelr,ModelMetrics,Metrics, tidyverse,simr,MASS)

#data
data = read.csv("6columns.csv")

#prepare data
data$X = NULL
data$X.1 = NULL
data$rateH=as.numeric(data$rateH)
```


Hypothesis 1 models and cross-validation:
Temporal proximity = β0i + β1i*Tweet Rate +(1|User) +ε
Temporal proximity = β0i + β1i*Tweet rate + β2i*Tweet rate 2 + (1|User) +ε
Temporal proximity = β0i + β1i*Tweet rate + β2i*Tweet rate 2 + β3i*Tweet rate 3 + (1|User) +ε
Temporal proximity = β0i + β1i*Tweet rate + β2i*Tweet rate 2 + β3i*Tweet rate 3 + β4i*Tweet rate 4 + (1|User) +ε
Temporal proximity = β0i + β1i*Tweet rate + β2i*log(Tweet rate)+ (1|User) +ε

```{r}
#Preperations for loop - result lists and n reset
rmse_train = NULL
rmse_test = NULL
n=1
SCORES = as.data.frame(NULL)

#Create list of the models to test. TRYING OUT WITH JUST TWO
Ms = c("proximity~rateH+(1|Name)",
       "proximity~1+rateH+I(rateH^2)+(1|Name)"
       )

#Create numeric ID corresponding to days as numbers to use in folding
data$day<- as.factor(data$day)
data$fold_id = as.numeric(data$day)

#Run Loop for all models, RESULTING VECTORS ARE TOO BIG
for (M in Ms) {
  #Create folds
  Folds = createFolds(unique(data$fold_id), 4)
  #Preperations for loop - result lists and n reset
  rmse_train = NULL
  rmse_test = NULL
  n=1
  
  for (i in Folds) {
    #Make a test dataset with one fold
    dtest_temp = subset(data, fold_id %in% i)
    #Make a training dataset with all other folds
    dtrain_temp = subset(data, !fold_id %in% i)
    
    View(dtest_temp)
    View(dtrain_temp)
    #Make a model on the training dataset
    model_temp = lmer(M, data=dtrain_temp)
    print(summary(model_temp))
    
    #Check error between fit of training data and actual training data
    #rmse_train[n] = Metrics :: rmse(dtrain_temp$proximity, fitted(model_temp))
    
    #Check error between predicitions for test data and actual test data
    #rmse_test[n] = Metrics :: rmse(dtest_temp$proximity, predict(model_temp, dtest_temp, allow.new.levels=T)) 
  
      #Loop end and n+1
    n=n+1
  }
  #Create row with results from model
  NewRow = data.frame(Model = M, rmse_train = mean(rmse_train), rmse_test = mean(rmse_test))
  #Add to final dataframe with all models
  SCORES = rbind(SCORES, NewRow) 
}

```

